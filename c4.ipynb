{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I was helping at some friends' garage sale, and saw the game Connect 4 lying in a pile of old board games to be sold for a dollar. One of the friends mentioned they \n",
    "\n",
    "This game is a great candidate for a \"toy\" reinforcement learning problem for a few reasons:\n",
    "* **The state space of the game is discrete and finite**, being simply the $6 \\times 7$ rectangular array of tokens. Each slot in the array is either empty (0) or is occupied by a red (1) or black (2) token. Thus, the state space is the set of 42-vectors whose components are either 0, 1, or 2. There are thus at most $3^{42}$ possible states of the board, though most of these will never occur in the normal course of gameplay (for example, the board consisting of all red tokens).\n",
    "* **The agents know the state entirely**.\n",
    "* **The dynamics of the game are deterministic and known**: when a token is placed in a column, it falls to the bottom of the column, without fail. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is one issue: to apply standard tabular value function methods, each agent would need to maintain a value for every of the $3^{42}$ states. This is an astronomically large number. We will need to use some value function approximation in order to make this problem tractable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from typing import Tuple, Any\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class C4Grid:\n",
    "    def __init__(self):\n",
    "        self._grid_size = torch.Size([6,7])\n",
    "        self._nwin = 4\n",
    "        self._grid_state = torch.zeros(self._grid_size, dtype=torch.int8)\n",
    "        self._player_chars = { 0: ' ', 1: 'O', 2: 'X' }\n",
    "        self._complete_flag = False\n",
    "\n",
    "\n",
    "    def restart(self) -> None:\n",
    "        print('Restarting board!')\n",
    "        self._complete_flag = False\n",
    "        self._grid_state = torch.zeros(self._grid_size, dtype=torch.int8)\n",
    "\n",
    "\n",
    "    def make_move(self, player: int, move_column: int) -> Tuple[int, Any, bool]:\n",
    "        \"\"\"Make a move.\n",
    "        \n",
    "            Returns:\n",
    "                int: reward for the move.\n",
    "                Any: state of the board after the move.\n",
    "                bool: True if game is won by this move.\n",
    "        \"\"\"\n",
    "        if self._complete_flag:\n",
    "            raise GameCompleteError('Game is complete!')\n",
    "\n",
    "        if not self.__is_valid_move(move_column):\n",
    "            # move is invalid: \n",
    "            # raise ValueError(\"Move invalid!\")\n",
    "            return -1_000, self._emit_state(), False\n",
    "        else:\n",
    "            # make the move\n",
    "            mr, _ = self.__drop_token(p=player, mc=move_column)\n",
    "            # check if game is won\n",
    "            if self._is_game_won(mr=mr, mc=move_column):\n",
    "                self._complete_flag = True\n",
    "                return 100, self._emit_state(), True\n",
    "            elif self._is_game_draw():\n",
    "                self._complete_flag = True\n",
    "                return 0, self._emit_state(), True\n",
    "        return 0, self._emit_state(), False\n",
    "\n",
    "\n",
    "    def __is_valid_move(self, mc: int) -> bool:\n",
    "        \"\"\"Verify if move is valid, given the state of the board.\"\"\"\n",
    "        if not isinstance(mc, int) or mc < 0 or mc >= self._grid_size[1]:\n",
    "            return False\n",
    "        if not self._grid_state[0, mc] == 0:\n",
    "            return False\n",
    "        return True\n",
    "\n",
    "\n",
    "    def __drop_token(self, p: int, mc: int) -> Tuple[int, int]:\n",
    "        \"\"\"Drop a token into a valid column.\n",
    "        \n",
    "            Starts at bottom row and moves up the rows, checking.\n",
    "            Assumes that the column is not empty.\n",
    "\n",
    "        Returns:\n",
    "            (row, col) where the move placed a token\n",
    "        \"\"\"\n",
    "        i = self._grid_size[0] - 1\n",
    "        while (self._grid_state[i, mc] != 0):\n",
    "            i -= 1\n",
    "        self._grid_state[i, mc] = p\n",
    "        return (i, mc)\n",
    "\n",
    "\n",
    "    def print_board(self) -> None:\n",
    "        \"\"\"Print a representation of the board to the console.\"\"\"\n",
    "        # print(self._grid_state)\n",
    "        nrows, ncols = self._grid_size\n",
    "        print('----' * ncols + '-')\n",
    "        for r in range(nrows):\n",
    "                self.__print_row_moves(r)\n",
    "                self.__print_row_lines()\n",
    "    \n",
    "\n",
    "    def __print_row_moves(self, r: int) -> None:\n",
    "        row_chars = [\n",
    "            self._player_chars[self._grid_state[r,c].item()]\n",
    "            for c in range(self._grid_size[1])\n",
    "            ]\n",
    "        row_str = ' | '.join(row_chars)\n",
    "        print('| ' + row_str + ' |')\n",
    "\n",
    "\n",
    "    def __print_row_lines(self) -> None:\n",
    "        print('-' * (4 * self._grid_size[1] + 1))\n",
    "\n",
    "    @property\n",
    "    def complete(self):\n",
    "        return self._complete_flag\n",
    "\n",
    "\n",
    "    def _is_game_won(self, mr: int, mc: int) -> Tuple[bool, int]:\n",
    "        \"\"\"Check if game is won after player made move in move column mc.\n",
    "        \n",
    "            Since we are checking after a particular player's move, we need\n",
    "            only check in the vicinity of that move, i.e., we can simply\n",
    "            check if that move was a winning move, rather than check the\n",
    "            entirety of the board.\n",
    "        \"\"\"\n",
    "        return True if any([\n",
    "            self.__check_row(mr, mc),\n",
    "            self.__check_col(mr, mc),\n",
    "            self.__check_diags(mr, mc),\n",
    "            ]) else False\n",
    "\n",
    "\n",
    "    def _is_game_draw(self):\n",
    "        \"\"\"Check if the game is a draw.\"\"\"\n",
    "        return not (self._grid_state == 0).any()\n",
    "\n",
    "\n",
    "    def __check_row(self, mr: int, mc: int) -> bool:\n",
    "        ptok = self._grid_state[mr, mc]  # player token\n",
    "        cmin = max(0, mc - (self._nwin - 1))\n",
    "        while cmin + self._nwin <= self._grid_size[1]:\n",
    "            if all(self._grid_state[mr, cmin:cmin+self._nwin] == ptok):\n",
    "                return True\n",
    "            cmin += 1\n",
    "        return False\n",
    "\n",
    "\n",
    "    def __check_col(self, mr: int, mc: int) -> bool:\n",
    "        ptok = self._grid_state[mr, mc]  # player token\n",
    "        rmin = max(0, mr - 3)\n",
    "        while rmin + self._nwin <= self._grid_size[0]:\n",
    "            if all(self._grid_state[rmin:rmin+self._nwin, mc] == ptok):\n",
    "                return True\n",
    "            rmin += 1\n",
    "        return False\n",
    "\n",
    "    \n",
    "    def __check_downward_diag(self, gs: torch.tensor, mr: int, mc: int, ptok: int):\n",
    "        # downward diagonal\n",
    "        i = 0\n",
    "        rmin = mr\n",
    "        cmin = mc\n",
    "        # find upper-leftmost point\n",
    "        while i < 3 and rmin - i > 0 and cmin - i > 0:\n",
    "            i += 1\n",
    "        rmin = rmin - i\n",
    "        cmin = cmin - i\n",
    "        \n",
    "        while (\n",
    "            rmin + self._nwin <= self._grid_size[0] and\n",
    "            cmin + self._nwin <= self._grid_size[1]\n",
    "            ):\n",
    "            if all(\n",
    "                gs[\n",
    "                    rmin:rmin+self._nwin,\n",
    "                    cmin:cmin+self._nwin\n",
    "                ].diag() == ptok\n",
    "                ):\n",
    "                return True\n",
    "            rmin += 1\n",
    "            cmin += 1\n",
    "        return False\n",
    "\n",
    "    def __check_diags(self, mr: int, mc: int) -> bool:\n",
    "        \"\"\"Check both diagonals.\"\"\"\n",
    "        ptok = self._grid_state[mr, mc]  # player token\n",
    "\n",
    "        return (\n",
    "            self.__check_downward_diag(\n",
    "                gs=self._grid_state,\n",
    "                mr=mr,\n",
    "                mc=mc,\n",
    "                ptok=ptok,\n",
    "                )\n",
    "            or\n",
    "            self.__check_downward_diag(\n",
    "                gs=torch.flip(self._grid_state, dims=[1]),\n",
    "                mr=self._grid_size[0] - mr,\n",
    "                mc=self._grid_size[0] - mc,\n",
    "                ptok=ptok,\n",
    "                )\n",
    "        )\n",
    "\n",
    "    def _emit_state(self):\n",
    "        \"\"\"Emit the game state. To be consumed by the agent(s).\"\"\"\n",
    "        return deepcopy(self._grid_state)\n",
    "\n",
    "\n",
    "class GameCompleteError(Exception):\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------\n",
      "|   |   |   |   |   |   |   |\n",
      "-----------------------------\n",
      "|   |   |   |   |   |   |   |\n",
      "-----------------------------\n",
      "| O |   |   |   |   |   |   |\n",
      "-----------------------------\n",
      "| O |   |   |   |   |   |   |\n",
      "-----------------------------\n",
      "| O |   |   |   |   |   |   |\n",
      "-----------------------------\n",
      "| O |   |   |   |   |   |   |\n",
      "-----------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "game = C4Grid()\n",
    "\n",
    "game.make_move(1, 0)\n",
    "game.make_move(1, 0)\n",
    "game.make_move(1, 0)\n",
    "game.make_move(1, 0)\n",
    "\n",
    "game.print_board()\n",
    "\n",
    "game.complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------\n",
      "|   |   |   |   |   |   |   |\n",
      "-----------------------------\n",
      "| O |   |   |   |   |   |   |\n",
      "-----------------------------\n",
      "| X | O |   |   |   |   |   |\n",
      "-----------------------------\n",
      "| X | X | O |   |   |   |   |\n",
      "-----------------------------\n",
      "| X | X | X | O |   |   |   |\n",
      "-----------------------------\n",
      "| O | X | X | O |   |   |   |\n",
      "-----------------------------\n"
     ]
    }
   ],
   "source": [
    "game = C4Grid()\n",
    "\n",
    "game.make_move(1, 0)\n",
    "game.make_move(2, 0)\n",
    "game.make_move(2, 0)\n",
    "game.make_move(2, 0)\n",
    "game.make_move(1, 0)\n",
    "\n",
    "game.make_move(2, 1)\n",
    "game.make_move(2, 1)\n",
    "game.make_move(2, 1)\n",
    "game.make_move(1, 1)\n",
    "\n",
    "game.make_move(2, 2)\n",
    "game.make_move(2, 2)\n",
    "game.make_move(1, 2)\n",
    "\n",
    "game.make_move(1, 3)\n",
    "game.make_move(1, 3)\n",
    "\n",
    "game.print_board()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class C4Agent:\n",
    "    def __init__(self):\n",
    "        self._t: int = 0  # time (num moves)\n",
    "        self._n_actions = 7\n",
    "        self.reward = 0\n",
    "\n",
    "    def policy(self, state: Any = None) -> int:\n",
    "        \"\"\"Mapping of (enviroment) states to agent's actions.\"\"\"\n",
    "        # random policy\n",
    "        return int(np.random.choice(a=range(self._n_actions)))\n",
    "\n",
    "\n",
    "agent = C4Agent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Player 1\tselected move:  3\treward:     0 (total:     0)\n",
      "Player 2\tselected move:  1\treward:     0 (total:     0)\n",
      "Player 1\tselected move:  0\treward:     0 (total:     0)\n",
      "Player 2\tselected move:  4\treward:     0 (total:     0)\n",
      "Player 1\tselected move:  3\treward:     0 (total:     0)\n",
      "Player 2\tselected move:  4\treward:     0 (total:     0)\n",
      "Player 1\tselected move:  3\treward:     0 (total:     0)\n",
      "Player 2\tselected move:  1\treward:     0 (total:     0)\n",
      "Player 1\tselected move:  0\treward:     0 (total:     0)\n",
      "Player 2\tselected move:  4\treward:     0 (total:     0)\n",
      "Player 1\tselected move:  5\treward:     0 (total:     0)\n",
      "Player 2\tselected move:  1\treward:     0 (total:     0)\n",
      "Player 1\tselected move:  2\treward:     0 (total:     0)\n",
      "Player 2\tselected move:  2\treward:     0 (total:     0)\n",
      "Player 1\tselected move:  4\treward:     0 (total:     0)\n",
      "Player 2\tselected move:  6\treward:     0 (total:     0)\n",
      "Player 1\tselected move:  0\treward:     0 (total:     0)\n",
      "Player 2\tselected move:  2\treward:     0 (total:     0)\n",
      "Player 1\tselected move:  0\treward:   100 (total:   100)\n",
      "Game is complete!\n",
      "Player 1 wins!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "niter = 0\n",
    "nitermax = 10\n",
    "game = C4Grid()\n",
    "\n",
    "player_1 = C4Agent()\n",
    "player_2 = C4Agent()\n",
    "\n",
    "state = game._emit_state()\n",
    "try:\n",
    "    while niter < nitermax:\n",
    "        p1_move = player_1.policy(state=state)\n",
    "        p1_reward, state, _ = game.make_move(1, move_column=p1_move)\n",
    "        player_1.reward += p1_reward\n",
    "        print(f'Player 1\\tselected move: {p1_move:2d}\\treward: {p1_reward:5d} (total: {player_1.reward:5d})')\n",
    "        \n",
    "        p2_move = player_2.policy(state=state)\n",
    "        p2_reward, state, _ = game.make_move(2, move_column=p2_move)\n",
    "        player_2.reward += p2_reward\n",
    "        print(f'Player 2\\tselected move: {p2_move:2d}\\treward: {p2_reward:5d} (total: {player_2.reward:5d})')\n",
    "    niter += 1\n",
    "    print('Iterations over, game incomplete!')\n",
    "except GameCompleteError:\n",
    "    print('Game is complete!')\n",
    "    if player_1.reward > player_2.reward:\n",
    "        print('Player 1 wins!')\n",
    "    elif player_1.reward < player_2.reward:\n",
    "        print('Player 2 wins!')\n",
    "    else:\n",
    "        print('Game is a draw.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------\n",
      "|   |   |   |   |   |   |   |\n",
      "-----------------------------\n",
      "|   |   |   |   |   |   |   |\n",
      "-----------------------------\n",
      "| O |   |   |   | O |   |   |\n",
      "-----------------------------\n",
      "| O | X | X | O | X |   |   |\n",
      "-----------------------------\n",
      "| O | X | X | O | X |   |   |\n",
      "-----------------------------\n",
      "| O | X | O | O | X | O | X |\n",
      "-----------------------------\n"
     ]
    }
   ],
   "source": [
    "game.print_board()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn\n",
    "import torch.nn.functional\n",
    "\n",
    "class C4AgentNN:\n",
    "    def __init__(self):\n",
    "        self._t: int = 0  # time (num moves)\n",
    "        self._n_actions = 7\n",
    "        self.reward = 0\n",
    "\n",
    "    def policy(self, state: Any = None) -> int:\n",
    "        \"\"\"Mapping of (enviroment) states to agent's actions.\"\"\"\n",
    "        # random policy\n",
    "        return int(np.random.choice(a=range(self._n_actions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DQN, self).__init__()\n",
    "        self.lin1 = torch.nn.Linear(in_features=6*7, out_features=6*5)\n",
    "        self.lin2 = torch.nn.Linear(in_features=6*5, out_features=6*3)\n",
    "        self.lin3 = torch.nn.Linear(in_features=6*3, out_features=7)\n",
    "\n",
    "    # Called with either one element to determine next action, or a batch\n",
    "    # during optimization. Returns tensor([[left0exp,right0exp]...]).\n",
    "    def forward(self, x):\n",
    "        # x = x.to(device)\n",
    "        x = torch.nn.functional.relu(self.lin1(x))\n",
    "        x = torch.nn.functional.relu(self.lin2(x))\n",
    "        x = torch.nn.functional.relu(self.lin3(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.2020, 0.0000, 0.1648, 0.3150, 0.2519, 0.0999, 0.1664],\n",
       "       grad_fn=<ReluBackward0>)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dqn = DQN()\n",
    "dqn.forward(game._emit_state().flatten().float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ab15d2006d0478514b7de1941ce9f837eff32d2ee58c111cc087075236e4cee2"
  },
  "kernelspec": {
   "display_name": "Python 3.9.13 ('rlenv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
